{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0md9re01ABZA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from SupConLosszy import SupConLoss\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jILqYvcjABZD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing............................\n",
      "torch.Size([10309, 1, 28, 28]) torch.Size([2578, 1, 28, 28]) torch.Size([10309]) torch.Size([2578])\n",
      "All down Train Data: 10309\n",
      "Real train Data: 8923\n",
      "All testsetA Data: 2578\n",
      "Real testsetA Data: 2226\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing............................')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from time import perf_counter\n",
    "\n",
    "import  numpy as np\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Safeman(Dataset):\n",
    "    \n",
    "    def __init__(self, data,targets):\n",
    "        super(Safeman, self).__init__()\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = self.data[idx], self.targets[idx]\n",
    "        return img, target\n",
    "\n",
    "class Safeman_Filter(Safeman):\n",
    "\n",
    "    def __Filter__(self, known):\n",
    "        targets = self.targets.data.numpy()\n",
    "        mask, new_targets = [], []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in known:\n",
    "                mask.append(i)\n",
    "                new_targets.append(known.index(targets[i]))\n",
    "        self.targets = np.array(new_targets)\n",
    "        mask = torch.tensor(mask).long()\n",
    "        self.data = torch.index_select(self.data, 0, mask)\n",
    "        \n",
    "class Safeman_FilterB(Safeman):\n",
    "\n",
    "    def __Filter__(self, known):\n",
    "        targets = self.targets.data.numpy()\n",
    "        new_targets = []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in known:\n",
    "                new_targets.append(0)\n",
    "            else:\n",
    "                new_targets.append(1)\n",
    "        self.targets = np.array(new_targets)\n",
    "        self.data = self.data\n",
    "\n",
    "class Safeman_FilterC(Safeman):\n",
    "    \n",
    "    def __Filter__(self, trainknown):\n",
    "        train_class_num=len(trainknown)\n",
    "        for i in range(0,len(self.targets)) :\n",
    "            if self.targets[i]>train_class_num:\n",
    "                self.targets[i] = train_class_num\n",
    "        self.data = self.data\n",
    "\n",
    "        \n",
    "def setup_seed(seed):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(8)\n",
    "\n",
    "\n",
    "\n",
    "known=[0, 1, 2,3,4]\n",
    "unknown=[ 5,6,7]\n",
    "\n",
    "num_class=len(known)\n",
    "\n",
    "\n",
    "\n",
    "X_train0 = np.load('./UKM/X_train_ukm.npy')\n",
    "y_train1 = np.load('./UKM/y_train_ukm.npy')\n",
    "X_final_test0 = np.load('./UKM/X_final_test_ukm.npy' )\n",
    "y__final_test1 = np.load('./UKM/y__final_test_ukm.npy')\n",
    "\n",
    "X_train1=[]\n",
    "X_final_test1=[]\n",
    "\n",
    "for i in range(len(y_train1)):\n",
    "    a = np.resize(X_train0[i], (1, 28, 28))\n",
    "    X_train1 += [a]\n",
    "    \n",
    "for j in range(len(y__final_test1)):\n",
    "    b = np.resize(X_final_test0[j], (1, 28, 28))\n",
    "    X_final_test1 += [b]\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train,y_test = torch.Tensor(X_train1), torch.Tensor(X_final_test1), torch.from_numpy(y_train1), torch.from_numpy(y__final_test1)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape,y_test.shape)\n",
    "\n",
    "train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "train_dataset.data = train_dataset.tensors[0]\n",
    "train_dataset.targets = train_dataset.tensors[1]\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "test_dataset.data = test_dataset.tensors[0]\n",
    "test_dataset.targets = test_dataset.tensors[1]\n",
    "\n",
    "\n",
    "labels =['ARP poisining', 'BeEF HTTP exploits','Mass HTTP requests','Metasploit exploits','Normal','Port scanning','TCP flood','UDP data flood']\n",
    "\n",
    "\n",
    "\n",
    "train_dataset.classes = labels\n",
    "test_dataset.classes = labels\n",
    "\n",
    "train_dataset.classes_to_idx = {i: label for i, label in enumerate(labels)}\n",
    "test_dataset.classes_to_idx = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "\n",
    "\n",
    "b_s=16\n",
    "\n",
    "trainset = Safeman_Filter(data=train_dataset.data,targets=train_dataset.targets)\n",
    "print('All down Train Data:', len(trainset))\n",
    "trainset.__Filter__(known=known)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=b_s, shuffle=True,\n",
    "    num_workers=4,drop_last=True)\n",
    "\n",
    "\n",
    "print('Real train Data:', len(trainset))\n",
    "\n",
    "\n",
    "\n",
    "testsetA = Safeman_Filter(data=test_dataset.data,targets=test_dataset.targets)\n",
    "print('All testsetA Data:', len(testsetA))\n",
    "testsetA.__Filter__(known=known)\n",
    "\n",
    "\n",
    "test_loader_A = torch.utils.data.DataLoader(\n",
    "    testsetA, batch_size=b_s, shuffle=True,\n",
    "    num_workers=4,drop_last=True)\n",
    "\n",
    "\n",
    "print('Real testsetA Data:', len(testsetA))\n",
    "\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import mnist\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class Modelnsl8(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, num_class) \n",
    "      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x4=x\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x3=x\n",
    "        feat = F.normalize(x3,dim=1)\n",
    "        x = self.fc4(x)\n",
    "        return feat,F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plUxoFLQABZH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 35.921024322509766\n",
      "epoch i= 1\n",
      "this train epoch end\n",
      "accuracy: 0.841\n",
      "idx: 0, loss: 33.20359420776367\n",
      "epoch i= 2\n",
      "this train epoch end\n",
      "accuracy: 0.927\n",
      "idx: 0, loss: 32.46283721923828\n",
      "epoch i= 3\n",
      "this train epoch end\n",
      "accuracy: 0.946\n",
      "idx: 0, loss: 33.24770736694336\n",
      "epoch i= 4\n",
      "this train epoch end\n",
      "accuracy: 0.988\n",
      "idx: 0, loss: 33.06803894042969\n",
      "epoch i= 5\n",
      "this train epoch end\n",
      "accuracy: 0.991\n",
      "idx: 0, loss: 28.88053321838379\n",
      "epoch i= 6\n",
      "this train epoch end\n",
      "accuracy: 0.992\n",
      "idx: 0, loss: 31.79766273498535\n",
      "epoch i= 7\n",
      "this train epoch end\n",
      "accuracy: 0.990\n",
      "idx: 0, loss: 29.600116729736328\n",
      "epoch i= 8\n",
      "this train epoch end\n",
      "accuracy: 0.991\n",
      "idx: 0, loss: 31.985748291015625\n",
      "epoch i= 9\n",
      "this train epoch end\n",
      "accuracy: 0.977\n",
      "idx: 0, loss: 33.674434661865234\n",
      "epoch i= 10\n",
      "this train epoch end\n",
      "accuracy: 0.992\n",
      "idx: 0, loss: 29.970869064331055\n",
      "epoch i= 11\n",
      "this train epoch end\n",
      "accuracy: 0.994\n",
      "idx: 0, loss: 31.778223037719727\n",
      "epoch i= 12\n",
      "this train epoch end\n",
      "accuracy: 0.991\n",
      "idx: 0, loss: 31.776878356933594\n",
      "epoch i= 13\n",
      "this train epoch end\n",
      "accuracy: 0.992\n",
      "idx: 0, loss: 30.785511016845703\n",
      "epoch i= 14\n",
      "this train epoch end\n",
      "accuracy: 0.987\n",
      "idx: 0, loss: 30.55467987060547\n",
      "epoch i= 15\n",
      "this train epoch end\n",
      "accuracy: 0.989\n",
      "idx: 0, loss: 29.588382720947266\n",
      "epoch i= 16\n",
      "this train epoch end\n",
      "accuracy: 0.992\n",
      "idx: 0, loss: 27.341205596923828\n",
      "epoch i= 17\n",
      "this train epoch end\n",
      "accuracy: 0.993\n",
      "idx: 0, loss: 30.765911102294922\n",
      "epoch i= 18\n",
      "this train epoch end\n",
      "accuracy: 0.988\n",
      "idx: 0, loss: 31.773204803466797\n",
      "epoch i= 19\n",
      "this train epoch end\n",
      "accuracy: 0.991\n",
      "idx: 0, loss: 32.59490203857422\n",
      "epoch i= 20\n",
      "this train epoch end\n",
      "accuracy: 0.995\n",
      "idx: 0, loss: 30.764081954956055\n",
      "epoch i= 21\n",
      "this train epoch end\n",
      "accuracy: 0.995\n",
      "idx: 0, loss: 28.465988159179688\n",
      "epoch i= 22\n",
      "this train epoch end\n",
      "accuracy: 0.996\n",
      "idx: 0, loss: 31.98808479309082\n",
      "epoch i= 23\n",
      "this train epoch end\n",
      "accuracy: 0.997\n",
      "idx: 0, loss: 29.57302474975586\n",
      "epoch i= 24\n",
      "this train epoch end\n",
      "accuracy: 0.997\n",
      "idx: 0, loss: 33.043216705322266\n",
      "epoch i= 25\n",
      "this train epoch end\n",
      "accuracy: 0.997\n",
      "idx: 0, loss: 29.8179931640625\n",
      "epoch i= 26\n",
      "this train epoch end\n",
      "accuracy: 0.998\n",
      "idx: 0, loss: 30.763582229614258\n",
      "epoch i= 27\n",
      "this train epoch end\n",
      "accuracy: 0.997\n",
      "idx: 0, loss: 28.57225227355957\n",
      "epoch i= 28\n",
      "this train epoch end\n",
      "accuracy: 0.997\n",
      "idx: 0, loss: 26.967050552368164\n",
      "epoch i= 29\n",
      "this train epoch end\n",
      "accuracy: 1.000\n",
      "training end\n"
     ]
    }
   ],
   "source": [
    "train_loader2 = train_loader\n",
    "test_loader2 = test_loader_A\n",
    "model = Modelnsl8()\n",
    "sgd = SGD(model.parameters(), lr=1e-2)\n",
    "criterion = SupConLoss(temperature=0.7)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "all_epoch = 29\n",
    "batch_size = b_s\n",
    "for current_epoch in range(all_epoch):\n",
    "    model.train()\n",
    "    for idx, (train_x, train_label) in enumerate(train_loader2):\n",
    "        sgd.zero_grad()\n",
    "        features1,predict_y = model(train_x.float().view(-1, 28*28))\n",
    "        \n",
    "        features=torch.cat([features1, features1], dim=0)\n",
    "        f1, f2 = torch.split(features, [batch_size, batch_size], dim=0)\n",
    "        feat = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)         \n",
    "        target2=train_label\n",
    "        loss2 = criterion(feat, target2)\n",
    "        loss1 = loss_fn(predict_y, train_label.long())\n",
    "        loss=loss1+loss2\n",
    "        if current_epoch > 20 :\n",
    "            sgd = SGD(model.parameters(), lr=1e-3)\n",
    "        if idx % 1000 == 0:\n",
    "            print('idx: {}, loss: {}'.format(idx, loss.sum().item()))\n",
    "        loss.backward()\n",
    "        sgd.step()\n",
    "    print(\"epoch i=\",current_epoch+1)\n",
    "    print(\"this train epoch end\")\n",
    "    all_correct_num = 0\n",
    "    all_sample_num = 0\n",
    "    model.eval()\n",
    "    for idx, (test_x, test_label) in enumerate(test_loader2):\n",
    "        _,predict_y = model(test_x.float().view(-1, 28*28))\n",
    "        predict_y=predict_y.detach()\n",
    "        predict_y = np.argmax(predict_y, axis=-1)\n",
    "        current_correct_num = predict_y == test_label\n",
    "        all_correct_num += np.sum(current_correct_num.numpy(), axis=-1)\n",
    "        all_sample_num += current_correct_num.shape[0]\n",
    "    acc = all_correct_num / all_sample_num\n",
    "    print('accuracy: {:.3f}'.format(acc))\n",
    "print(\"training end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JsMI1aQABZu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Capsule Network.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
